{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51a754-6779-4987-9e43-cf9a0cda220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7de2f979-46ba-4e33-86fe-33bf2fe37528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# for creating a dataframe \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef88b8f-a40e-4ea0-864e-ed458d178972",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sebi.gov.in/sebiweb/other/OtherAction.do?doPmr=yes\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "response = requests.get(url)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "22d3de05-f7e4-4b8d-b8a3-3417bc28eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predefined DataFrames with column names\n",
    "\n",
    "table1 = [\"Name of the Portfolio Manager\",\t\"Registration Number\",\t\"Date of Registration\",\t\"Registered Address of the Portfolio Manager\",\t\"Name of Principal Officer\",\t\"Email ID of the Principal Officer\",\t\"Contact Number (Direct) of the Principal Officer\",\t\"Name of Compliance Officer\",\t\"Email ID of the Compliance Officer\",\t\"No. of clients as on last day of the month\", \"Total Assets under Management (AUM) as on last day of the month (Amount in INR crores)\"]\n",
    "df = pd.DataFrame(columns = table1)\n",
    "# df\n",
    "\n",
    "table2 = [\"No_of_unique_PF/EPFO\",\t\"No_of_unique_Corporates\",\t\"No_of_unique_Non-Corporates\",\t\"No_of_unique_Non-Residents\", \"No_of_unique_FPI\",\t\"No_of_unique_Others\",\t\"No_of_unique_total\",\t\"AUM_PF/EPFO\",\t\"AUM_Corporates\",\t\"AUM_Non-Corporates\", \"AUM_Non-Residents\",\t\"AUM_FPI\",\t\"AUM_Others\",\t\"AUM_total\"]\n",
    "df2 = pd.DataFrame(columns = table2)\n",
    "# df2\n",
    "\n",
    "table3 = [\"Discretionary_Equity Listed\",\t\"Discretionary_Equity Unlisted\",\t\"Discretionary_Plain Debt Listed\",\t\"Discretionary_Plain Debt Unlisted\",\t\"Discretionary_Structured Debt Listed\",\t\"Discretionary_Structured Debt Unlisted\",\t\"Discretionary_Derivatives Equity\",\t\"Discretionary_Derivatives Commodity\",\t\"Discretionary_Derivatives Others\",\t\"Discretionary_Mutual Funds\",\t\"Discretionary_Others\",\t\"Discretionary_Total\",\t\"Non-Discretionary_Equity Listed\",\t\"Non-Discretionary_Equity Unlisted\",\t\"Non-Discretionary_Plain Debt Listed\",\t\"Non-Discretionary_Plain Debt Unlisted\",\t\"Non-Discretionary_Structured Debt Listed\",\t\"Non-Discretionary_Structured Debt Unlisted\",\t\"Non-Discretionary_Derivatives Equity\",\t\"Non-Discretionary_Derivatives Commodity\",\t\"Non-Discretionary_Derivatives Others\",\t\"Non-Discretionary_Mutual Funds\",\t\"Non-Discretionary_Others\",\t\"Non-Discretionary_Total\",\t\"Advisory_Total\"]\n",
    "df3 = pd.DataFrame(columns = table3)\n",
    "# df3\n",
    "\n",
    "table4 =  [\"A_No_of_unique_PF/EPFO\",\t\"A_No_of_unique_Corporates\",\t\"A_No_of_unique_Non-Corporates\",\t\"A_No_of_unique_Non-Residents\",\t\"A_No_of_unique_FPI\",\t\"A_No_of_unique_Others\",\t\"A_No_of_unique_total\",\t\"A_AUM_PF/EPFO\",\t\"A_AUM_Corporates\",\t\"A_AUM_Non-Corporates\",\t\"A_AUM_Non-Residents\",\"A_AUM_FPI\",\t\"A_AUM_Others\",\t\"A_AUM_total\"]\n",
    "df4 = pd.DataFrame(columns = table4)\n",
    "# df4\n",
    "\n",
    "table5 =  [\"F_No_of_unique_PF/EPFO\",\t\"F_No_of_unique_Corporates\",\t\"F_No_of_unique_Non-Corporates\",\t\"F_No_of_unique_Non-Residents\",\t\"F_No_of_unique_FPI\",\t\"F_No_of_unique_Others\",\t\"F_No_of_unique_total\",\t\"F_AUM_PF/EPFO\",\t\"F_AUM_Corporates\",\t\"F_AUM_Non-Corporates\",\t\"F_AUM_Non-Residents\",\t\"F_AUM_FPI\",\t\"F_AUM_Others\",\t\"F_AUM_total\"]\n",
    "df5 = pd.DataFrame(columns = table5)\n",
    "# df5\n",
    "\n",
    "table6 =  [\"g_Equity Listed\",\t\"g_Equity Unlisted\",\t\"g_Plain Debt Listed\",\t\"g_Plain Debt Unlisted\",\t\"g_Structured Debt Listed\",\t\"g_Structured Debt Unlisted\",\t\"g_Derivatives Equity\",\t\"g_Derivatives Commodity\", \"g_Derivatives Others\",\t\"g_Mutual Funds\",\t\"g_Others\",\t\"g_Total\"]\n",
    "df6 = pd.DataFrame(columns = table6)\n",
    "# df6\n",
    "\n",
    "table7 =  [\"h_Inflow_during_the_month\",\t\"h_Outflow_during_the_month\",\t\"h_Net_flow_during_the_month\",\t\"h_Inflow_during_the_FY\",\t\"h_Outflow_during_the_FY\",\t\"h_Net_flow_during_the_FY\"]\n",
    "df7 = pd.DataFrame(columns = table7)\n",
    "# df7\n",
    "\n",
    "table8 =  [\"k_No_of_clients_PF/EPFO\",\t\"k_No_of_clients_Corporates\",\t\"k_No_of_clients_Non-Corporates\",\t\"k_No_of_clients_Non-Residents\",\t\"k_No_of_clients_FPI\",\t\"k_No_of_clients_Others\",\t\"k_No_of_clients_total\",\t\"k_Value_of_the_Assets_PF/EPFO\",\t\"k_Value_of_the_Assets_Corporates\",\t\"k_Value_of_the_Assets_Non-Corporates\",\t\"k_Value_of_the_Assets_Non-Residents\",\t\"k_Value_of_the_Assets_FPI\",\t\"k_Value_of_the_Assets_Others\",\t\"k_Value_of_the_Assets_total\"]\n",
    "df8 = pd.DataFrame(columns = table8)\n",
    "# df8\n",
    "\n",
    "df9 = pd.DataFrame(columns = [\"table_b\"])\n",
    "# df9\n",
    "df10 = pd.DataFrame(columns = [\"table_c\"])\n",
    "# df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "964c8720-f2a4-4698-a84d-1ef6e4bde938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# to get an idea about the number of fields present there, find out all the fields present over there\n",
    "\n",
    "n_list = driver.find_elements(By.XPATH, '//select[@name=\"pmrId\"]')\n",
    "name_list = []\n",
    "for i in n_list:\n",
    "    name_list = i.text.split(\"\\n\")\n",
    "len_name = len(new_list)\n",
    "print(len_name) #this is the length of the fields present over there\n",
    "# print(new_list[112])\n",
    "# print(new_list)\n",
    "\n",
    "#selecting year\n",
    "year = driver.find_element(By.NAME,\"year\")\n",
    "yr_ele = Select(year)\n",
    "yr_ele.select_by_visible_text(\"2024\")\n",
    "\n",
    "#selecting month\n",
    "month = driver.find_element(By.NAME,\"month\")\n",
    "mn_ele = Select(month)\n",
    "mn_ele.select_by_visible_text(\"June\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb536fdb-e61a-4bbb-b2b9-f6e409f0a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop for the number of elements in the dropdown section\n",
    "\n",
    "for num in range(1,len_name+1):\n",
    "    name = driver.find_element(By.NAME,\"pmrId\")\n",
    "    name_ele = Select(name)\n",
    "    name_ele.select_by_visible_text(name_list[num])\n",
    "\n",
    "    go = driver.find_element(By.XPATH,'//div[@class=\"go_area go-area\"]')\n",
    "    # print(go.text)\n",
    "    go.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Get the page source after clicking the button\n",
    "    html = driver.page_source\n",
    "    \n",
    "    # Parse the HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        #Finding table and extract data from it \n",
    "        tab1 = soup.find_all(\"table\")[0]\n",
    "        data1 = tab1.find_all(\"td\")\n",
    "        data1_ = []\n",
    "        for i in data1:\n",
    "            data1_.append(i.text.strip())\n",
    "        len_ = len(df)\n",
    "        df.loc[len_] = data1_\n",
    "\n",
    "        tab2 = soup.find_all(\"table\")[1]\n",
    "        data2 = tab2.find_all(\"td\")\n",
    "        data2_ = []\n",
    "        for i in data2:\n",
    "            data2_.append(i.text.strip())\n",
    "        len_ = len(df2)\n",
    "        df2.loc[len_] = data2_[1:8] + data2_[9:16]\n",
    "\n",
    "        tab3 = soup.find_all(\"table\")[2]\n",
    "        data3 = tab3.find_all(\"td\")\n",
    "        data3_ = []\n",
    "        for i in data3:\n",
    "            data3_.append(i.text.strip())\n",
    "        n_data3 = data3_[1:13] + data3_[14:26]\n",
    "        n_data3.append(data3_[-1])\n",
    "        len_ = len(df3)\n",
    "        df3.loc[len_] = n_data3\n",
    "\n",
    "        tab4 = soup.find_all(\"table\")[4]\n",
    "        data4 = tab4.find_all(\"td\")\n",
    "        data4_ = []\n",
    "        for i in data4:\n",
    "            data4_.append(i.text.strip())\n",
    "        len_ = len(df3)\n",
    "        df4.loc[len_] = data4_[1:8] + data4_[9:16]\n",
    "\n",
    "        tab5 = soup.find_all(\"table\")[10]\n",
    "        data5 = tab5.find_all(\"td\")\n",
    "        data5_ = []\n",
    "        for i in data5:\n",
    "            data5_.append(i.text.strip())\n",
    "        len_ = len(df5)\n",
    "        df5.loc[len_] = data5_[1:8] + data5_[9:16]\n",
    "        \n",
    "        tab6 = soup.find_all(\"table\")[11]\n",
    "        data6 = tab6.find_all(\"th\")\n",
    "        data6_ = []\n",
    "        for i in data6:\n",
    "            data6_.append(i.text.strip())\n",
    "        len_ = len(df6)\n",
    "        df6.loc[len_] = data6_[-12:]\n",
    "        \n",
    "        tab7 = soup.find_all(\"table\")[12]\n",
    "        data7 = tab7.find_all(\"td\")\n",
    "        data7_ = []\n",
    "        for i in data7:\n",
    "            data7_.append(i.text.strip())\n",
    "        len_ = len(df7)\n",
    "        df7.loc[len_] = data7_[-6:]\n",
    "        \n",
    "        tab8 = soup.find_all(\"table\")[15]\n",
    "        data8 = tab8.find_all(\"td\")\n",
    "        data8_ = []\n",
    "        for i in data8:\n",
    "            data8_.append(i.text.strip())\n",
    "        len_ = len(df8)\n",
    "        df8.loc[len_] = data8_[1:8] + data8_[9:16]\n",
    "\n",
    "\n",
    "    except Exception:\n",
    "        df.loc[len_] = None\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141fee6-2988-4ed8-bc3d-634fbc617f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all the DataFrames and save to .csv file\n",
    "result = pd.concat([df, df2, df3, df4, df5, df6, df7, df8], axis=1)\n",
    "\n",
    "df.to_excel('SEBI_Gov_Scrapped_Data.xlsx', index=False)\n",
    "\n",
    "print(\"Table scraped and saved to 'scraped_table.xlsx'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
